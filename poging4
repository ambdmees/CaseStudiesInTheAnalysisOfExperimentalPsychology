#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May 18 11:50:52 2021

@author: amberdemeester
"""


import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedShuffleSplit
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
#from sklearn.ensemble import RandomForestClassifier
#from sklearn.svm import SVC
#from sklearn import svm
#from sklearn.neural_network import MLPClassifier
#from sklearn.metrics import confusion_matrix, classification_report
#from sklearn.preprocessing import StandardScaler, LabelEncoder
#from sklearn.model_selection import train_test_split
# Load dataset
data = pd.read_csv('/Users/amberdemeester/Desktop/02MA - EXPERIMENTAL PSYCHOLOGY/Case Studies Experimental Psychology/Dataset/StudentsPerformance.csv', sep = ';')
data.head()


#Split dataset
split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)

for train_index,test_index in split.split(data,data["Race"]):
    train_set = data.loc[train_index]
    test_set = data.loc[test_index]
    
#Visualise the data
data.info() #it's also important to know with which kind of data you're dealing with, here we can see that we have 1000 rows and 9 columns out of which 3 ara int type and rest are of object type
data.isnull().sum() #So our data frame contains only Non Null values, this is important because otherwise you have to filter the non-values out

fig = make_subplots(rows=2, cols=5, shared_yaxes=True,
                    subplot_titles=("entire data","entire data", "entire data", "entire data", "entire data",
                                   "testing data","testing data", "testing data", "testing data", "testing data"))

def add_attr_trace(fig, dataset, attr, r, c):
    fig.add_trace(go.Histogram(x=dataset[attr].sort_values(), histnorm='probability', name=attr), row=r, col=c)
    
attrs = data.columns[:5]

for i in range(len(attrs)):
    add_attr_trace(fig, data, attrs[i], 1, i + 1)
    add_attr_trace(fig, test_set, attrs[i], 2, i + 1)

fig.update_layout(showlegend=False, height=900)
fig.show()
sns.set_style('darkgrid')
sns.countplot(y= 'Gender', data = data, palette = 'colorblind')
plt.xlabel('Count')
plt.ylabel('Gender')
plt.show()

#calculating the female and male count
female_count = len(data[data['Gender']== 'female']) 
male_count = 1000 - female_count
print("female count is:", female_count, "\n", "male count is:", male_count)

sns.set_style('whitegrid')
sns.countplot(x='Race',data=data,palette='colorblind')
plt.xlabel("Race")
plt.ylabel("Count")
plt.show()

sns.set_style('whitegrid')
sns.countplot(y='ParentalLevelOfEducation',data=data,palette='colorblind')
plt.xlabel("Count")
plt.ylabel("Parental Level of Education")
plt.show()

sns.set_style('whitegrid')
sns.countplot(y='Lunch',data=data,palette='colorblind')
plt.xlabel("Count")
plt.ylabel("Lunch")
plt.show()

sns.set_style('whitegrid')
sns.countplot(y='TestPreparationScore',data=data,palette='colorblind')
plt.ylabel("Test Preparation Course")
plt.xlabel("Count")
plt.show()

sns.set_style('darkgrid')
plt.title('Maths score vs Reading score',size=16)
plt.xlabel('Maths Score',size=12)
plt.ylabel('Reading Score',size=12)
sns.scatterplot(x='MathScore',y='ReadingScore',data =data,hue='Gender',edgecolor='black',palette='cubehelix',hue_order=['male','female'])
plt.show()

sns.set_style('whitegrid')
plt.title('Maths score vs Writing score',size=16)
plt.xlabel('Maths score',size=12)
plt.ylabel('Writing score',size=12)
sns.scatterplot(x='MathScore',y='WritingScore',data =data,hue='Gender',s=90,edgecolor='black',palette='cubehelix',hue_order=['male','female'])
plt.show()

sns.set_style('whitegrid')
plt.title('Reading score vs Writing score',size=16)
plt.xlabel('Reading score',size=12)
plt.ylabel('Writing score',size=12)
sns.scatterplot(x='ReadingScore',y='WritingScore',data =data,hue='Gender',s=90,edgecolor='black',palette='colorblind',hue_order=['male','female'])
plt.show()

#total marks are score of all subjects out of 100
TotalMarks = ((data['MathScore'] + data['ReadingScore'] + data['WritingScore'])/300)*100 
data['TotalMarks'] = TotalMarks
kde_data = data[['MathScore','ReadingScore','WritingScore','TotalMarks']]

sns.set_style("darkgrid")
sns.kdeplot(data=kde_data,shade=True,palette='colorblind')
plt.show()

sns.catplot(x='Race',y='TotalMarks',data =data,hue='TestPreparationScore',palette='colorblind',kind='box',showfliers=False)
plt.xlabel("Race/Ethnicity")
plt.ylabel("Total Marks")
plt.show()

plt.rcParams["figure.figsize"] = (8, 4)  
plt.rcParams["xtick.labelsize"] = 5
order = ["master's degree","bachelor's degree","associate's degree","some college","high school","some high school"]
sns.catplot(x='ParentalLevelOfEducation',y='TotalMarks',data =data,hue='TestPreparationScore',order=order,palette='Dark2_r',kind='box',showfliers=False)
plt.xlabel("Parental Level of Education")
plt.ylabel("Total Marks")
plt.show()

sns.catplot(x='ParentalLevelOfEducation',y='TotalMarks',hue='Lunch',data=data,order=order,palette='cubehelix')
plt.xlabel("Parental Level of Education")
plt.ylabel("Total Marks")
plt.show()

#prepare data
X_train = train_set.drop(['MathScore', 'ReadingScore', 'WritingScore'], axis=1)
y_train_math = train_set['MathScore'].copy()
y_train_reading = train_set['ReadingScore'].copy()
y_train_writing = train_set['WritingScore'].copy()

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

category_attrs = attrs

full_pipeline = ColumnTransformer([('category', OneHotEncoder(), category_attrs)])

X_train = full_pipeline.fit_transform(X_train)

##training models
#lineair regression
from sklearn.linear_model import LinearRegression

lin_regr_math = LinearRegression()
lin_regr_math.fit(X_train, y_train_math)

lin_regr_reading = LinearRegression()
lin_regr_reading.fit(X_train, y_train_reading)

lin_regr_writing = LinearRegression()
lin_regr_writing.fit(X_train, y_train_writing)

#Decision Tree Regressor
from sklearn.tree import DecisionTreeRegressor

tree_regr_math = DecisionTreeRegressor(random_state=42)
tree_regr_math.fit(X_train, y_train_math)

tree_regr_reading = DecisionTreeRegressor(random_state=42)
tree_regr_reading.fit(X_train, y_train_reading)

tree_regr_writing = DecisionTreeRegressor(random_state=42)
tree_regr_writing.fit(X_train, y_train_writing)

#Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor

forest_regr_math = RandomForestRegressor(random_state=42)
forest_regr_math.fit(X_train, y_train_math)

forest_regr_reading = RandomForestRegressor(random_state=42)
forest_regr_reading.fit(X_train, y_train_math)

forest_regr_writing = RandomForestRegressor(random_state=42)
forest_regr_writing.fit(X_train, y_train_math)


##Predict training data
from sklearn.metrics import mean_squared_error

def predict(model, X, y, tag):
    predictions = model.predict(X)
    mse = mean_squared_error(y, predictions)
    rmse = np.sqrt(mse)
    print('prediction for ' + tag + ': rmse = ', rmse)
    
#Linear models
print('Linear Regression ----------------')
predict(lin_regr_math, X_train, y_train_math, 'MathScore')
predict(lin_regr_reading, X_train, y_train_reading, 'ReadingScore')
predict(lin_regr_writing, X_train, y_train_writing, 'WritingScore')

#Decision tree models
print('Decision Tree Regressor  ----------------')
predict(tree_regr_math, X_train, y_train_math, 'MathScore')
predict(tree_regr_reading, X_train, y_train_reading, 'ReadingScore')
predict(tree_regr_writing, X_train, y_train_writing, 'WritingScore')

#Random forst models
print('Random Forest Regressor ----------------')
predict(forest_regr_math, X_train, y_train_math, 'MathScore')
predict(forest_regr_reading, X_train, y_train_reading, 'ReadingScore')
predict(forest_regr_writing, X_train, y_train_writing, 'WritingScore')

##Cross validation
def display_scores(scores):
    print('Scores:', scores)
    print('Mean:', scores.mean())
    print('Standard deviation:', scores.std())

def apply_cross_validation(estimator, X, y, tag):
    scores = cross_val_score(estimator, X, y, scoring='neg_mean_squared_error', cv=10)
    rmse_scores = np.sqrt(-scores)
    print()
    print('********** ' + tag + ' **********')
    display_scores(rmse_scores)

from sklearn.model_selection import cross_val_score

print()
print('cross validation for linear regressions -----------------------------')
apply_cross_validation(lin_regr_math, X_train, y_train_math, 'MathScore')
apply_cross_validation(lin_regr_reading, X_train, y_train_reading, 'ReadingScore')
apply_cross_validation(lin_regr_writing, X_train, y_train_writing, 'WritingScore')

print()
print('cross validation for decision tree regressors -----------------------------')
apply_cross_validation(tree_regr_math, X_train, y_train_math, 'MathScore')
apply_cross_validation(tree_regr_reading, X_train, y_train_reading, 'ReadingScore')
apply_cross_validation(tree_regr_writing, X_train, y_train_writing, 'WritingScore')

print()
print('cross validation for random forest regressors -----------------------------')
apply_cross_validation(forest_regr_math, X_train, y_train_math, 'MathScore')
apply_cross_validation(forest_regr_reading, X_train, y_train_reading, 'ReadingScore')
apply_cross_validation(forest_regr_writing, X_train, y_train_writing, 'WritingScore')

#Getting better models
from sklearn.model_selection import GridSearchCV

def grid_search_cv(estimator, param_grid, X, y, tag):
    print()
    print(tag + ' ----------------------------------')
    
    grid_search = GridSearchCV(estimator, param_grid, verbose=1, cv=10,
                              scoring='neg_mean_squared_error',
                              return_train_score=True, refit=True)

    grid_search.fit(X, y)
    print()
    print('best_params_: ')
    print(grid_search.best_params_)
    
    results = grid_search.cv_results_
    for mean_score, params in zip(results['mean_test_score'], results['params']):
        print(np.sqrt(-mean_score), params)
        
    feature_importances = grid_search.best_estimator_.feature_importances_
    print()
    print('feature_importances: ')
    print(feature_importances)
    
    return grid_search

print('Grid search for decision tree regressors -------------------------------')
param_grid = {'max_depth': list(range(2, 10)), 'min_samples_split': [2, 3, 4, 5, 6]}
grid_search_tree_math = grid_search_cv(DecisionTreeRegressor(random_state=42), param_grid, X_train, y_train_math, 'MathScore')
grid_search_tree_reading = grid_search_cv(DecisionTreeRegressor(random_state=42), param_grid, X_train, y_train_reading, 'ReadingScore')
grid_search_tree_writing = grid_search_cv(DecisionTreeRegressor(random_state=42), param_grid, X_train, y_train_writing, 'WritingScore')


print()
print('Grid search for random forest regressors -------------------------------')
param_grid = {'max_depth': list(range(2, 10)), 'min_samples_split': [2, 3, 4, 5, 6]}
grid_search_forest_math = grid_search_cv(RandomForestRegressor(random_state=42), param_grid, X_train, y_train_math, 'MathScore')
grid_search_forest_reading = grid_search_cv(RandomForestRegressor(random_state=42), param_grid, X_train, y_train_reading, 'ReadingScore')
grid_search_forest_writing = grid_search_cv(RandomForestRegressor(random_state=42), param_grid, X_train, y_train_writing, 'WritingScore')

#Final testing
def final_predict(grid_search, X, y, tag):
    predictions = grid_search.best_estimator_.predict(X)
    mse = mean_squared_error(y, predictions)
    rmse = np.sqrt(mse)
    print('final predict for ' + tag + ': rmse = ', rmse)
    
X_test = test_set.drop(['MathScore', 'ReadingScore', 'WritingScore'], axis=1)
y_test_math = test_set['MathScore'].copy()
y_test_reading = test_set['ReadingScore'].copy()
y_test_writing = test_set['WritingScore'].copy()
X_test = full_pipeline.transform(X_test)

print('Linear Regression  ----------------')
predict(lin_regr_math, X_test, y_test_math, 'MathScore')
predict(lin_regr_reading, X_test, y_test_reading, 'ReadingScore')
predict(lin_regr_writing, X_test, y_test_writing, 'WritingScore')

print()
print('Decision Tree Regressor  ----------------')
predict(tree_regr_math, X_test, y_test_math, 'MathScore')
predict(tree_regr_reading, X_test, y_test_reading, 'ReadingScore')
predict(tree_regr_writing, X_test, y_test_writing, 'WritingScore')

print()
print('Fine-tuned Decision Tree Regressor  ----------------')
final_predict(grid_search_tree_math, X_test, y_test_math, 'MathScore')
final_predict(grid_search_tree_reading, X_test, y_test_reading, 'ReadingScore')
final_predict(grid_search_tree_writing, X_test, y_test_writing, 'WritingScore')

print()
print('Random Forest Regressor ----------------')
predict(forest_regr_math, X_test, y_test_math, 'MathScore')
predict(forest_regr_reading, X_test, y_test_reading, 'ReadingScore')
predict(forest_regr_writing, X_test, y_test_writing, 'WritingScore')

print()
print('Fine-tuned Random Forest Regressor  ----------------')
final_predict(grid_search_forest_math, X_test, y_test_math, 'MathScore')
final_predict(grid_search_forest_reading, X_test, y_test_reading, 'ReadingScore')
final_predict(grid_search_forest_writing, X_test, y_test_writing, 'WritingScore')